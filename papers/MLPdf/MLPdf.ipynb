{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPdf: An Effective Machine Learning Based Approach for PDF Malware Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "- User Authentication (Supabase Auth)\n",
    "- PDF Malware Detection\n",
    "- PDF Statistics (percentage why it's Benign or Malicious)\n",
    "- Sign of saved PDF with Digital Signature (if privyID can provide API??)\n",
    "- Save signed PDF on Database (Supabase for now)\n",
    "- Optional: Face Signature??\n",
    "\n",
    "## TODO\n",
    "- Optimally Preprocessing Data\n",
    "- Supabase Auth\n",
    "- TensorFlow Model vs Transfer Learning\n",
    "- Statistics parameter\n",
    "- Signature DrawBox\n",
    "- Temporary Database with Deadlines\n",
    "- Face Feature as Signed PDF UUID\n",
    "\n",
    "## Tech Stack\n",
    "- Streamlit vs Taipy\n",
    "- FastAPI\n",
    "- Supabase\n",
    "- TensorFlow\n",
    "- Others Statistics libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset from official repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-19 02:13:01--  http://205.174.165.80/CICDataset/CIC-EvasivePDF2022/Dataset/Benign.zip\n",
      "Connecting to 205.174.165.80:80... connected.\n",
      "HTTP request sent, awaiting response... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adalgiso/.pyenv/versions/3.11.7/lib/python3.11/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 OK\n",
      "Length: 753571486 (719M) [application/zip]\n",
      "Saving to: ‘../../datasets/PDFBenign.zip’\n",
      "\n",
      "../../datasets/PDFB 100%[===================>] 718.66M   233KB/s    in 61m 28s \n",
      "\n",
      "2024-04-19 03:14:30 (200 KB/s) - ‘../../datasets/PDFBenign.zip’ saved [753571486/753571486]\n",
      "\n",
      "--2024-04-19 03:14:30--  http://205.174.165.80/CICDataset/CIC-EvasivePDF2022/Dataset/Malicious.zip\n",
      "Connecting to 205.174.165.80:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 503579900 (480M) [application/zip]\n",
      "Saving to: ‘../../datasets/PDFMalicious.zip’\n",
      "\n",
      "../../datasets/PDFM 100%[===================>] 480.25M   233KB/s    in 49m 21s \n",
      "\n",
      "2024-04-19 04:03:52 (166 KB/s) - ‘../../datasets/PDFMalicious.zip’ saved [503579900/503579900]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# just save the dataset on local storage, for saving cost ;)\n",
    "# SO THE DIRECTORY are based on LOCAL WORKSPACE\n",
    "# JUST FOR MODEL and FEATURE DEVELOPMENT\n",
    "!wget --no-check-certificate \\\n",
    "  http://205.174.165.80/CICDataset/CIC-EvasivePDF2022/Dataset/Benign.zip \\\n",
    "  -O ../../datasets/PDFBenign.zip\n",
    "\n",
    "!wget --no-check-certificate \\\n",
    "  http://205.174.165.80/CICDataset/CIC-EvasivePDF2022/Dataset/Malicious.zip \\\n",
    "  -O ../../datasets/PDFMalicious.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os, sys, shutil, urllib.request, zipfile, tarfile\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Extraction: Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip_L1(pdfClass: str) -> str:\n",
    "    # pdfClass: PDFBenign & PDFMalicious\n",
    "    dpath = 'datasets/CICDatasets'\n",
    "    if not dpath.is_dir():\n",
    "        os.makedirs(dpath, exist_ok=True)\n",
    "\n",
    "    zip_path = dpath.parent / f'{pdfClass}.zip'\n",
    "    if not zip_path.exists():\n",
    "        return f\"File not found: {zip_path}\"\n",
    "\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip:\n",
    "            zip.extractall(path = dpath / f'{pdfClass}')\n",
    "        zip.close()\n",
    "        # os.remove(zip_path)\n",
    "\n",
    "        extracted_path = dpath / f'{pdfClass}'\n",
    "        index = 1\n",
    "        for filename in os.listdir(extracted_path):\n",
    "            old_path = os.path.join(extracted_path / filename)\n",
    "            new_path = os.path.join(extracted_path, f\"{pdfClass}_{index}.zip\")\n",
    "            os.rename(old_path, new_path)\n",
    "            index += 1\n",
    "        return f\"Extraction L1: {pdfClass}.zip completed successfully\"\n",
    "\n",
    "    except Exception as e:\n",
    "        exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "        # fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "        # print(exc_type, fname, )\n",
    "        return f\"An error occurred: In line [{exc_tb.tb_lineno}] {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Extraction: Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip_L2(pdfClass: str) -> str:\n",
    "    L1_DIR = Path(os.getcwd()).resolve().parent.parent / 'datasets/CICDatasets'\n",
    "    fpath = L1_DIR / f'{pdfClass}'\n",
    "    try:\n",
    "        for filename in os.listdir(fpath):\n",
    "            if filename.endswith(\".zip\"):\n",
    "                zip_file_path = fpath / filename\n",
    "                sub_folder = fpath / os.path.splitext(os.path.basename(filename))[0]\n",
    "                if not sub_folder.is_dir():\n",
    "                    try:\n",
    "                        with zipfile.ZipFile(zip_file_path, 'r') as zip:\n",
    "                            zip.extractall(path=sub_folder)\n",
    "\n",
    "                        # Delete the zip file after extraction\n",
    "                        os.remove(zip_file_path)\n",
    "\n",
    "                    # Handle bad zip files\n",
    "                    except zipfile.BadZipfile as e:\n",
    "                        print(\"BAD ZIP: \" + str(zip_file_path))\n",
    "                        try:\n",
    "                            os.remove(zip_file_path)\n",
    "                        except OSError as e:\n",
    "                            if e.errno != errno.ENOENT:\n",
    "                                raise\n",
    "\n",
    "        length_dir = len(os.listdir(fpath))\n",
    "        message = f\"The {pdfClass}.zip files successfully extracted. The length of directories: {length_dir}\"\n",
    "        return message\n",
    "\n",
    "    except Exception as e:\n",
    "        exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "        # fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "        # print(exc_type, fname, )\n",
    "        return f\"An error occurred: In line [{exc_tb.tb_lineno}]: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the extractions from L1 to L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "benign_L1 = extract_zip_L1(pdfClass =  'PDFBenign')\n",
    "malicious_L1 = extract_zip_L1(pdfClass =  'PDFMalicious')\n",
    "\n",
    "benign_L2 = extract_zip_L2(pdfClass =  'PDFBenign')\n",
    "malicious_L2 = extract_zip_L2(pdfClass =  'PDFMalicious')\n",
    "\n",
    "print(benign_L1)\n",
    "print(malicious_L1)\n",
    "print(benign_L2)\n",
    "print(malicious_L2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Implementations that will be applied:\n",
    "- Shapes of Data\n",
    "- PDF extraction sample\n",
    "- Traditional Detection\n",
    "- Malicious Statistics and differenciate with Benign Statistics\n",
    "- Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spliting_data(self) -> str:\n",
    "    fpath = Path(f\"{self.curr_path}/data/{self.pdf_type}\")\n",
    "\n",
    "    train_dir = Path(fpath / 'train')\n",
    "    test_dir = Path(fpath / 'test')\n",
    "\n",
    "    # Create train_dir if it doesn't exist\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "\n",
    "    # Create test_dir if it doesn't exist\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    # Record train and test directory to exclude from removing\n",
    "    exclude_dir = {train_dir, test_dir}\n",
    "\n",
    "    try:\n",
    "        # Create a filtered list of directories to process\n",
    "        directories_to_process = [folder for folder in os.listdir(\n",
    "            fpath) if Path(fpath, folder) not in exclude_dir]\n",
    "\n",
    "        for folder in directories_to_process:\n",
    "            # Full path to the subfolder\n",
    "            folder_path = os.path.join(fpath, folder)\n",
    "\n",
    "            # Listing all the subfolders\n",
    "            if os.path.isdir(folder_path):\n",
    "                files = os.listdir(folder_path)\n",
    "\n",
    "                # Split the files into train and test sets\n",
    "                train_files = files[:int(len(files) * self.split_ratio)]\n",
    "                test_files = files[int(len(files) * self.split_ratio):]\n",
    "\n",
    "                # Copy the train files to the train directory\n",
    "                for file in train_files:\n",
    "                    src_file_path = os.path.join(folder_path, file)\n",
    "                    dst_file_path = os.path.join(train_dir, file)\n",
    "                    shutil.move(src_file_path, dst_file_path)\n",
    "\n",
    "                # Copy the test files to the test directory\n",
    "                for file in test_files:\n",
    "                    src_file_path = os.path.join(folder_path, file)\n",
    "                    dst_file_path = os.path.join(test_dir, file)\n",
    "                    shutil.move(src_file_path, dst_file_path)\n",
    "\n",
    "            # Remove the source folder after splitting\n",
    "            shutil.rmtree(folder_path)\n",
    "        return f\"Splitting {self.pdf_type} is completed\"\n",
    "\n",
    "    except Exception as e:\n",
    "        exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "        # fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "        # print(exc_type, fname, )\n",
    "        return f\"An error occurred: In line [{exc_tb.tb_lineno}]: {str(e)}\"\n",
    "\n",
    "def get_file_byte_string(self, file) -> bytes:\n",
    "    curr_file = open(file, \"rb\")\n",
    "    data = curr_file.read()\n",
    "    data_str = str(data)\n",
    "    data_delim = ' '.join(data_str[i:i+4]\n",
    "                            for i in range(0, len(data_str), 4))\n",
    "    data_bytes = bytes(data_delim, 'utf-8')\n",
    "    curr_file.close()\n",
    "    return data_bytes\n",
    "\n",
    "def create_row(self, filetype, file, writer) -> None:\n",
    "    file_data = []\n",
    "    file_data.append(self.id_counter)\n",
    "    file_data.append(filetype)\n",
    "    file_data.append(os.path.basename(os.path.normpath(file)))\n",
    "    bytecode = self.get_file_byte_string(file)\n",
    "    file_data.append(bytecode)\n",
    "    writer.writerow(file_data)\n",
    "    file_data.clear()\n",
    "    self.id_counter += 1\n",
    "\n",
    "def csv_generator(self) -> None:\n",
    "\n",
    "    fpath = Path(f\"{self.curr_path}/data/{self.pdf_type}\")\n",
    "\n",
    "    with open('testing.csv', 'a+') as testing_csv:\n",
    "        writer = csv.writer(testing_csv)\n",
    "\n",
    "        writer.writerow(self.header)\n",
    "\n",
    "        for files in os.listdir(os.path.join(fpath, 'test')):\n",
    "\n",
    "            # put all this into \"do_list_creation(filetype, file) function\"\n",
    "            self.create_row(self.ftype, os.path.join(\n",
    "                fpath, 'test', files), writer)\n",
    "\n",
    "    with open('training.csv', 'a+') as training_csv:\n",
    "        writer = csv.writer(training_csv)\n",
    "        writer.writerow(self.header)\n",
    "        for files in os.listdir(os.path.join(fpath, 'train')):\n",
    "            self.create_row(self.ftype, os.path.join(\n",
    "                fpath, 'train', files), writer)\n",
    "\n",
    "    return \"Succesfully Completed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Detection Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLP Architecture](assets/mlp_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
